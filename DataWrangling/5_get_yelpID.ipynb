{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Yelp Matching IDs\n",
    "To get Yelp data, one first needs to match the DPH names with Yelp's restaurant ID's\n",
    "\n",
    "## Part 1: Using Old Data\n",
    "A 2020 version of the Yelp academic dataset contained Georgia. We can use this to get some ID's to reduce the number\n",
    "of API calls required. Yelp limits us to 5000 requests/day. Using fuzzy-matching on name and addresses, we get the\n",
    "best match."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "            dph_id                                         violations  \\\n0     MTE4MTc1Mg==  [8-2B, 11A, 15C, 4-2B, 15B, 17A, 17C, 17D, 11A...   \n1     MTE4MTc2MA==                                                 []   \n2     MTE4MTc2Nw==                                  [6-1A, 6-1C, 13A]   \n3     MTE4MTcxOA==                            [2-2D, 4-2B, 15A, 6-1A]   \n4     MTE4MTcyMQ==                                                 []   \n...            ...                                                ...   \n7837  OTQ5MzY3NA==                                                 []   \n7838  OTQ5MzY3NQ==  [2-2D, 4-2B, 6-2, 15C, 17C, 17C, 18, 4-2B, 17C...   \n7839  OTQ5MzcwNQ==  [3-1B, 8-2B, 2-2A, 2-2E, 5-1B, 11A, 3-1B, 11A,...   \n7840  OTQ5MzcwNw==                        [6-1A, 6-1B, 10D, 16A, 16B]   \n7841  OTQ5MzcwOQ==  [2-2A, 2-2E, 4-2B, 10D, 13A, 14C, 15A, 10D, 12...   \n\n      years_data  lifetime_count  \\\n0       2.230137              11   \n1       0.000000               0   \n2       0.000000               3   \n3       2.460274               4   \n4       0.613699               0   \n...          ...             ...   \n7837    0.000000               0   \n7838    2.893151              23   \n7839    1.997260              10   \n7840    2.569863               5   \n7841    2.435616              11   \n\n                                      lifetime_comments  lifetime_avg  \\\n0     Observed the concentration of the sanitizer in...     96.500000   \n1                                                          100.000000   \n2          See Attachment See Attachment See Attachment     88.000000   \n3     Observed Handwash sink in bar used as dumpsink...     93.333333   \n4                                                          100.000000   \n...                                                 ...           ...   \n7837                                                       100.000000   \n7838  Observed failure to have hand soap at sushi ba...     89.200000   \n7839  46F milk and 65F chicken wrap sandwich.  No de...     92.500000   \n7840  Observed various salsas and sour cream being s...     95.333333   \n7841  Observed PIC could not provide documentation o...     92.666667   \n\n      violation_rate  \n0           4.932432  \n1           0.000000  \n2           3.000000  \n3           1.625835  \n4           0.000000  \n...              ...  \n7837        0.000000  \n7838        7.949811  \n7839        5.006859  \n7840        1.945629  \n7841        4.516310  \n\n[7842 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dph_id</th>\n      <th>violations</th>\n      <th>years_data</th>\n      <th>lifetime_count</th>\n      <th>lifetime_comments</th>\n      <th>lifetime_avg</th>\n      <th>violation_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MTE4MTc1Mg==</td>\n      <td>[8-2B, 11A, 15C, 4-2B, 15B, 17A, 17C, 17D, 11A...</td>\n      <td>2.230137</td>\n      <td>11</td>\n      <td>Observed the concentration of the sanitizer in...</td>\n      <td>96.500000</td>\n      <td>4.932432</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MTE4MTc2MA==</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td></td>\n      <td>100.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MTE4MTc2Nw==</td>\n      <td>[6-1A, 6-1C, 13A]</td>\n      <td>0.000000</td>\n      <td>3</td>\n      <td>See Attachment See Attachment See Attachment</td>\n      <td>88.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MTE4MTcxOA==</td>\n      <td>[2-2D, 4-2B, 15A, 6-1A]</td>\n      <td>2.460274</td>\n      <td>4</td>\n      <td>Observed Handwash sink in bar used as dumpsink...</td>\n      <td>93.333333</td>\n      <td>1.625835</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>MTE4MTcyMQ==</td>\n      <td>[]</td>\n      <td>0.613699</td>\n      <td>0</td>\n      <td></td>\n      <td>100.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7837</th>\n      <td>OTQ5MzY3NA==</td>\n      <td>[]</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td></td>\n      <td>100.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7838</th>\n      <td>OTQ5MzY3NQ==</td>\n      <td>[2-2D, 4-2B, 6-2, 15C, 17C, 17C, 18, 4-2B, 17C...</td>\n      <td>2.893151</td>\n      <td>23</td>\n      <td>Observed failure to have hand soap at sushi ba...</td>\n      <td>89.200000</td>\n      <td>7.949811</td>\n    </tr>\n    <tr>\n      <th>7839</th>\n      <td>OTQ5MzcwNQ==</td>\n      <td>[3-1B, 8-2B, 2-2A, 2-2E, 5-1B, 11A, 3-1B, 11A,...</td>\n      <td>1.997260</td>\n      <td>10</td>\n      <td>46F milk and 65F chicken wrap sandwich.  No de...</td>\n      <td>92.500000</td>\n      <td>5.006859</td>\n    </tr>\n    <tr>\n      <th>7840</th>\n      <td>OTQ5MzcwNw==</td>\n      <td>[6-1A, 6-1B, 10D, 16A, 16B]</td>\n      <td>2.569863</td>\n      <td>5</td>\n      <td>Observed various salsas and sour cream being s...</td>\n      <td>95.333333</td>\n      <td>1.945629</td>\n    </tr>\n    <tr>\n      <th>7841</th>\n      <td>OTQ5MzcwOQ==</td>\n      <td>[2-2A, 2-2E, 4-2B, 10D, 13A, 14C, 15A, 10D, 12...</td>\n      <td>2.435616</td>\n      <td>11</td>\n      <td>Observed PIC could not provide documentation o...</td>\n      <td>92.666667</td>\n      <td>4.516310</td>\n    </tr>\n  </tbody>\n</table>\n<p>7842 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from yelpapi import YelpAPI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "gdf = pd.read_pickle('geocoded_df.pkl')\n",
    "rdf = pd.read_csv('restaurant_db.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T23:37:07.769774Z",
     "end_time": "2023-04-07T23:37:07.779702Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "from thefuzz import process\n",
    "\n",
    "def fuzzy_merge(df1, df2, key1, key2, threshold=80, limit=1):\n",
    "    s = df2[key2].tolist()\n",
    "    m = df1[key1].apply(lambda x: process.extract(x, s, limit=limit, ))\n",
    "    df1['matches'] = m\n",
    "    return df1\n",
    "\n",
    "# Make everything <name>,<addr> and lower for dph dataframe\n",
    "gdf['full_name'] = gdf[['name', 'map_add']].apply(lambda x: ', '.join([str(x[0]), str(x[1])]).lower(), axis=1)\n",
    "gdf\n",
    "\n",
    "# Do the same thing for yelp dataframe\n",
    "rdf['full_name'] = rdf[['name', 'address', 'city', 'state', 'postal_code']]\\\n",
    "    .apply(lambda x: ', '.join([str(i).lower() for i in x]), axis=1)\n",
    "rdf\n",
    "\n",
    "# Fuzzy merge the datasets (this process is very slow, unfortunately)\n",
    "fuzzy_merge(gdf, rdf, 'full_name', 'full_name', 80, 1)\n",
    "\n",
    "# Threshold based on the goodness of the match\n",
    "good_matches = gdf[gdf.apply(lambda x: x['matches'][0][1] >= 89, axis = 1)]\n",
    "\n",
    "# Extract the match name into its own column\n",
    "good_matches['match_name'] = good_matches.apply(lambda x: x['matches'][0][0], axis=1)\n",
    "\n",
    "# Ensure there are no duplicate matches\n",
    "uniq_matches = good_matches.drop_duplicates('match_name')\n",
    "uniq_rdf = rdf.drop_duplicates('full_name')\n",
    "\n",
    "# This gives us the final dataframe with Yelp business ID's\n",
    "final_matches = uniq_matches.merge(uniq_rdf[['business_id', 'full_name']], how='inner', left_on='match_name',\n",
    "                                   right_on='full_name',\n",
    "                                   validate='one_to_one')\n",
    "\n",
    "# Clean up unnecessary columns\n",
    "yelp1 = final_matches.drop(['full_name_x', 'matches', 'match_name', 'full_name_y'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:46:53.154868Z",
     "end_time": "2023-04-08T00:46:53.159805Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2: The Remainder\n",
    "We have no choice but to get the rest from the API"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Locate the entities which we do not yet have a Yelp ID for\n",
    "remaining_df = pd.merge(gdf, yelp1, indicator=True, how='outer', on='dph_id').query('_merge==\"left_only\"').drop('_merge', axis=1)\n",
    "remaining_df = remaining_df[['dph_id', 'map_add_x', 'name_x', 'lat_x', 'lng_x']]\n",
    "\n",
    "# Eliminate schools, hospitals, prisons, churches, and other institutions\n",
    "exclude = ['SCHOOL', 'MOBILE', 'BASE', 'CATER', 'ELEMENTARY', 'HOSPITAL', 'JAIL', 'JR. HIGH', 'REHABILITATION',\n",
    "           'TREATMENT', 'REGIONAL', 'SYNAGOGUE', 'SOCIETY', 'SENIOR', 'CENTER', 'BIBLE', 'CAMPUS', 'RETIREMENT',\n",
    "           'MANAGEMENT', 'MEDICINE', 'ACADEMY', 'DEPARTMENT']\n",
    "\n",
    "filtered = remaining_df[remaining_df.apply(lambda x: not any([y in x['name_x'].upper() for y in exclude]), axis=1)]\n",
    "\n",
    "# Normalize the addresses to use the business-match API endpoint\n",
    "rows = []\n",
    "for index, item in filtered.iterrows():\n",
    "    addr = item['map_add_x'].split(',')\n",
    "    if len(addr) == 3:\n",
    "        street = addr[0]\n",
    "        city = addr[1]\n",
    "    elif len(addr) == 4:\n",
    "        street = addr[0]\n",
    "        city = addr[2]\n",
    "    else:\n",
    "        street = addr[0] + addr[1]\n",
    "        city = addr[-2]\n",
    "    res = {\n",
    "        'dph_id': item['dph_id'],\n",
    "        'name': item['name_x'].lower(),\n",
    "        'street': street.lower(),\n",
    "        'city': city.lower(),\n",
    "        'state': 'GA',\n",
    "        'country': 'US'\n",
    "    }\n",
    "    rows.append(res)\n",
    "\n",
    "parsed_addr_df = pd.DataFrame.from_records(rows)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ask Yelp for the Data\n",
    "IMPORTANT: Since API Calls are limited, you may need to break this into two separate runs: one for the first half of\n",
    "the dataframe and another for the second half."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## First Part\n",
    "# frame = parsed_addr_df.iloc[906:]\n",
    "\n",
    "## Second Part\n",
    "frame = parsed_addr_df.iloc[4966:]\n",
    "\n",
    "api_key = \"qOWiNCp8Sblg84q0uiPRXiksxMk2DzMvMRnnSI29PxS-xv9sG9e4yxJ-lPHFaMHaacOJ8uBOZX4T1rY3fhnZTzzy4ZW2m_vT-WhnYgix5RSSc4VnFQw0-lQmQVQxZHYx\"\n",
    "responses = []\n",
    "for index, entity in tqdm(frame.iterrows(), total=frame.shape[0]):\n",
    "    try:\n",
    "        with YelpAPI(api_key) as yelp_api:\n",
    "            response = yelp_api.business_match_query(\n",
    "                name=entity['name'],\n",
    "                address1=entity['street'],\n",
    "                city=entity['city'],\n",
    "                state=entity['state'],\n",
    "                country=entity['country'],\n",
    "                limit=1,\n",
    "                match_threshold='strict'\n",
    "            )\n",
    "        row = {\n",
    "            'dph_id': entity['dph_id'],\n",
    "            'result': response\n",
    "        }\n",
    "    except Exception as e:\n",
    "        row = {\n",
    "            'dph_id': entity['dph_id'],\n",
    "            'result': []\n",
    "        }\n",
    "        print(e)\n",
    "    responses.append(row)\n",
    "    time.sleep(20/1000)\n",
    "\n",
    "part1_df = pd.DataFrame.from_records(responses)\n",
    "\n",
    "records = []\n",
    "for i, r in enumerate(responses):\n",
    "    record = {\n",
    "        'dph_id': parsed_addr_df.iloc[i]['dph_id'],\n",
    "        'yelp_resp': r\n",
    "    }\n",
    "    records.append(record)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "part1_df = pd.DataFrame.from_records(responses)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "part2_df = pd.DataFrame.from_records(responses)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "part3_df = pd.DataFrame.from_records(responses)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_df = pd.concat([part1_df.rename(columns={'dph_id':'dph_id', 'result':'yelp_resp'}), part2_df.rename\n",
    "(columns={'dph_id':'dph_id', 'result':'yelp_resp'}), part3_df.rename(columns={'dph_id':'dph_id', 'result':'yelp_resp'})], axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_df.to_pickle('yelp_responses_all.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# serialize the dataframe\n",
    "serialized = []\n",
    "\n",
    "for index, row in combined_df.iterrows():\n",
    "    try:\n",
    "        e = row['yelp_resp']['businesses']\n",
    "        if len(e) != 0:\n",
    "            s = {\n",
    "                'dph_id': row['dph_id'],\n",
    "                'yelp_id': e[0]['id'],\n",
    "                'yelp_name': e[0]['name']\n",
    "            }\n",
    "            serialized.append(s)\n",
    "    except Exception as e:\n",
    "        print(row, e, index)\n",
    "\n",
    "yelp_matches = pd.DataFrame.from_records(serialized)\n",
    "yelp_matches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combine with matches from academic dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "other_matches = pd.read_pickle('yelp_matched1.pkl')\n",
    "exclude = ['SCHOOL', 'MOBILE', 'BASE', 'CATER', 'ELEMENTARY', 'HOSPITAL', 'JAIL', 'JR. HIGH', 'REHABILITATION',\n",
    "           'TREATMENT', 'REGIONAL', 'SYNAGOGUE', 'SOCIETY', 'SENIOR', 'CENTER', 'BIBLE', 'CAMPUS', 'RETIREMENT',\n",
    "           'MANAGEMENT', 'MEDICINE', 'ACADEMY', 'DEPARTMENT']\n",
    "\n",
    "other_filtered = other_matches[other_matches.apply(lambda x: not any([y in str(x['name']).upper() for y in exclude]),axis=1)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_all_matches = pd.concat([yelp_matches, other_filtered[['dph_id', 'business_id']].rename\n",
    "(columns={'dph_id':'dph_id', 'business_id':'yelp_id'})], axis=0)\n",
    "combined_all_matches.drop_duplicates('yelp_id', inplace=True)\n",
    "combined_all_matches.to_pickle('all_yelp_ids.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "            dph_id                 yelp_id\n0     MTIzMDIzODE=  u_irrlZiHMa7ueeUHqHtvA\n1     MTIzMDI4MTI=  39r2fM5P8heVXlLgYkmSaA\n2     MTI3NzEzMjA=  QjL9fgvhsJta7SSX7P8YMw\n3     MTI3NzE5MzM=  c2Ta5My44Uz4tT_jrq6u5w\n4     MTI3NzIwOTA=  lhxEztxsao9WfyfWuSpJfw\n...            ...                     ...\n1574  Nzk1Mzg0NQ==  iJ1vqcHFhDSR-vunw7np-w\n1575  OTQ4NDkzOQ==  g0KkQmGXCtxkzHWoYEQa4A\n1576      ODg2NDA0  RE8bmfnqfcYEpbUHo3dYVQ\n1577  Nzk1NjQzMw==  t4M0yOSVLz59H7JQi3FUSQ\n1578  MTIyNzQwOTg=  WN4j8Bgc4Xex-HVIxPIi3w\n\n[4403 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dph_id</th>\n      <th>yelp_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MTIzMDIzODE=</td>\n      <td>u_irrlZiHMa7ueeUHqHtvA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MTIzMDI4MTI=</td>\n      <td>39r2fM5P8heVXlLgYkmSaA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MTI3NzEzMjA=</td>\n      <td>QjL9fgvhsJta7SSX7P8YMw</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MTI3NzE5MzM=</td>\n      <td>c2Ta5My44Uz4tT_jrq6u5w</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>MTI3NzIwOTA=</td>\n      <td>lhxEztxsao9WfyfWuSpJfw</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1574</th>\n      <td>Nzk1Mzg0NQ==</td>\n      <td>iJ1vqcHFhDSR-vunw7np-w</td>\n    </tr>\n    <tr>\n      <th>1575</th>\n      <td>OTQ4NDkzOQ==</td>\n      <td>g0KkQmGXCtxkzHWoYEQa4A</td>\n    </tr>\n    <tr>\n      <th>1576</th>\n      <td>ODg2NDA0</td>\n      <td>RE8bmfnqfcYEpbUHo3dYVQ</td>\n    </tr>\n    <tr>\n      <th>1577</th>\n      <td>Nzk1NjQzMw==</td>\n      <td>t4M0yOSVLz59H7JQi3FUSQ</td>\n    </tr>\n    <tr>\n      <th>1578</th>\n      <td>MTIyNzQwOTg=</td>\n      <td>WN4j8Bgc4Xex-HVIxPIi3w</td>\n    </tr>\n  </tbody>\n</table>\n<p>4403 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "combined_all_matches = pd.read_pickle('all_yelp_ids.pkl')\n",
    "combined_all_matches"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T19:34:54.608236Z",
     "end_time": "2023-04-11T19:34:54.651392Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
